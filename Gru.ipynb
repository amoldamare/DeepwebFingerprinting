{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzdata=np.load(\"data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=npzdata['data']\n",
    "labels=npzdata['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249996, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.sequence as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=sq.pad_sequences(data,maxlen=maxlen,padding='post',truncating='post',dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reshape(data.shape[0],data.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_labels=list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in set_labels:\n",
    "    dict_label[l]=n\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new=[]\n",
    "for l in labels:\n",
    "    labels_new.append(dict_label[l])\n",
    "\n",
    "label_1=np_utils.to_categorical(labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(data,labels,batch_size=32):\n",
    "    nb_instances = data.shape[0]\n",
    "    nb_classes = labels.shape[1]\n",
    "    sample_shape = data[0].shape\n",
    "    batch_data_shape = tuple([batch_size] + list(sample_shape))\n",
    "    batch_label_shape = (batch_size, nb_classes)\n",
    "    # Infinite loop\n",
    "    while True:\n",
    "        # Generate an exploration order\n",
    "        indices = np.arange(nb_instances)\n",
    "\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # Generate batches\n",
    "        imax = int(len(indices) / batch_size)\n",
    "        for i in range(imax):\n",
    "            # Form a batch\n",
    "            x = np.empty(batch_data_shape)\n",
    "            y = np.empty(batch_label_shape)\n",
    "            for j, k in enumerate(indices[i * batch_size: (i + 1) * batch_size]):\n",
    "                x[j] = data[k]\n",
    "                y[j] = labels[k]\n",
    "            if x.shape != batch_data_shape:\n",
    "                print(x.shape)\n",
    "                exit(0)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "input_length=maxlen\n",
    "input_dim=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(input_shape=(input_length,input_dim),units=128,activation='tanh',recurrent_activation='hard_sigmoid',return_sequences=True,dropout=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=128,activation='tanh',recurrent_activation='hard_sigmoid',return_sequences=False,dropout=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes=label_1.shape[1]\n",
    "model.add(Dense(units=nb_classes,activation='softmax'))\n",
    "metrics=['accuracy']\n",
    "optimizer=RMSprop(lr=0.001,decay=0.0)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 150, 128)          49920     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               13029     \n",
      "=================================================================\n",
      "Total params: 161,637\n",
      "Trainable params: 161,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test =model_selection.train_test_split(data, label_1, test_size=0.33)\n",
    "trainGen=generateData(X_train,y_train)\n",
    "valGen=generateData(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5234/5234 [==============================] - 2784s 532ms/step - loss: 2.7601 - acc: 0.3431 - val_loss: 1.3631 - val_acc: 0.6168\n",
      "Epoch 2/5\n",
      "5234/5234 [==============================] - 2683s 513ms/step - loss: 1.4155 - acc: 0.6595 - val_loss: 0.7413 - val_acc: 0.7935\n",
      "Epoch 3/5\n",
      "5234/5234 [==============================] - 2894s 553ms/step - loss: 0.8851 - acc: 0.7696 - val_loss: 0.9695 - val_acc: 0.7323\n",
      "Epoch 4/5\n",
      "5234/5234 [==============================] - 2817s 538ms/step - loss: 0.6933 - acc: 0.8184 - val_loss: 0.4740 - val_acc: 0.8667\n",
      "Epoch 5/5\n",
      "5234/5234 [==============================] - 2535s 484ms/step - loss: 0.6131 - acc: 0.8376 - val_loss: 0.4993 - val_acc: 0.8572\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=trainGen,steps_per_epoch=X_train.shape[0]//32,validation_data=valGen,validation_steps=X_test.shape[0]//32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
