{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Layer, Dense, TimeDistributed, Concatenate, InputSpec, Wrapper, RNN,Conv1D,Lambda,Add,Input\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(ScaledDotProductAttention,self).__init__(**kwargs)\n",
    "    def call(self,x):\n",
    "        \"\"\"\n",
    "            Attention(Q,K,V)=softmax(Q*K^T / sqrt(d_k))*V\n",
    "        \"\"\"\n",
    "        q,k,v=x\n",
    "        \n",
    "        d_k=q.shape.as_list()[2]\n",
    "        \n",
    "        weights=K.batch_dot(q,k,axes=[2,2])\n",
    "        \n",
    "        weights=K.softmax(weights/np.sqrt(d_k))\n",
    "        \n",
    "        output=K.batch_dot(weights,v)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self,h,d_k,**kwargs):\n",
    "        self.h=h\n",
    "        self.d_k=d_k\n",
    "        self.d_v=d_k\n",
    "        self.d_model=self.h*d_k\n",
    "        self._q_layers=[]\n",
    "        self._k_layers=[]\n",
    "        self._v_layers=[]\n",
    "        self.sdpa_layer=ScaledDotProductAttention()\n",
    "        self._output=TimeDistributed(Dense(self.d_model))\n",
    "        for _ in range(self.h):\n",
    "            self._q_layers.append(TimeDistributed(Dense(self.d_k,activation=\"relu\",use_bias=False)))\n",
    "            self._k_layers.append(TimeDistributed(Dense(self.d_k,activation=\"relu\",use_bias=False)))\n",
    "            self._v_layers.append(TimeDistributed(Dense(self.d_v,activation=\"relu\",use_bias=False)))\n",
    "            \n",
    "        super(MultiHeadAttention,self).__init__(**kwargs)\n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        super(MultiHeadAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self,x):\n",
    "        \"\"\"\n",
    "            MultiHeadAttention(q,k,v)=concat(head_1,...head_h)*W_0\n",
    "            head_i=Attention(q*W_q_i,k*W_k_i,v*W_v_i)\n",
    "        \"\"\"\n",
    "        [q,k,v]=x\n",
    "        \n",
    "        outputs=[]\n",
    "        attentions=[]\n",
    "        for i in range(self.h):\n",
    "            qi=self._q_layers[i](q)\n",
    "            ki=self._k_layers[i](k)\n",
    "            vi=self._v_layers[i](v)\n",
    "            output=self.sdpa_layer([qi,ki,vi])\n",
    "            outputs.append(output)\n",
    "        \n",
    "        concatenated_outputs=Concatenate()(outputs)\n",
    "        output=self._output(concatenated_outputs)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(Layer):\n",
    "    def __init__(self,d_model=512,d_ff=2048,**kwargs):\n",
    "        self.d_model=d_model,\n",
    "        self.d_ff=d_ff\n",
    "        self.conv1=Dense(units=d_ff,activation='relu')\n",
    "        self.conv2=Dense(units=d_model)\n",
    "        super(PositionWiseFeedForward,self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        super(PositionWiseFeedForward,self).build(input_shape)\n",
    "        \n",
    "    def call(self,x):\n",
    "        temp_x=self.conv1(x)\n",
    "    \n",
    "        x=self.conv2(temp_x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(Layer):\n",
    "    def __init__(self, eps=1e-6, **kwargs):\n",
    "        self.eps = eps\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
    "                                     initializer=Ones(), trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
    "                                    initializer=Zeros(), trainable=True)\n",
    "        super(LayerNormalization, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        mean = K.mean(x, axis=-1, keepdims=True)\n",
    "        std = K.std(x, axis=-1, keepdims=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer):\n",
    "    def __init__(self,h=8,d_k=64,d_hidden=2048,**kwargs):\n",
    "        self.h=h\n",
    "        self.d_k=d_k\n",
    "        self.d_model=self.h*self.d_k\n",
    "        \n",
    "        self.d_hidden=d_hidden\n",
    "        self.mha=MultiHeadAttention(self.h,self.d_k)\n",
    "        self.ln_1=LayerNormalization()\n",
    "        self.add_1=Add()\n",
    "        self.ffwd=PositionWiseFeedForward(d_model=self.d_model,d_ff=self.d_hidden)\n",
    "        self.ln_2=LayerNormalization()\n",
    "        self.add_2=Add()\n",
    "        super(EncoderLayer,self).__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def call(self,x):\n",
    "        y=self.mha([x,x,x])\n",
    "        \n",
    "        y=self.add_1([x,y])\n",
    "        y=self.ln_1(y)\n",
    "        \n",
    "        x=self.ffwd(y)\n",
    "        x=self.add_2([x,y])\n",
    "        y=self.ln_2(x)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Input(shape=(150,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=EncoderLayer(h=8,d_k=1,d_hidden=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_o=temp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(150), Dimension(8)])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(150), Dimension(1)])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(Layer):\n",
    "    def __init__(self,h=8,d_k=64,d_hidden=2048,**kwargs):\n",
    "        self.h=h\n",
    "        self.d_k=64\n",
    "        self.d_model=self.h*self.d_k\n",
    "        self.d_hidden=d_hidden\n",
    "        self.mha_1=MultiHeadAttention(self.h,self.d_k)\n",
    "        self.ln_1=LayerNormalization()\n",
    "        self.add_1=Add()\n",
    "        self.mha_2=MultiHeadAttention(self.h,self.d_k)\n",
    "        self.ln_2=LayerNormalization()\n",
    "        self.add_2=Add()\n",
    "        self.ffwd=PositionWiseFeedForward(d_model=self.d_model,d_ff=self.d_hidden)\n",
    "        self.ln_3=LayerNormalization()\n",
    "        self.add_3=Add()\n",
    "        super(DecoderLayer,self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self,inp):\n",
    "        x,encoder_output=inp\n",
    "        y=self.mha_1([x,x,x])\n",
    "        y=self.add_1([x,y])\n",
    "        y=self.ln_1(y)\n",
    "        \n",
    "        x=self.mha_2([encoder_output,encoder_output,y])\n",
    "        x=self.add_2([x,y])\n",
    "        x=self.ln_2(x)\n",
    "        \n",
    "        y=self.ffwd(x)\n",
    "        y=self.add_3([x,y])\n",
    "        y=self.ln_3(y)\n",
    "        \n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(self,n=6,h=8,d_k=64,d_hidden=2048,**kwargs):\n",
    "        self.n=n\n",
    "        self.h=h\n",
    "        self.d_k=d_k\n",
    "        self.d_hidden=d_hidden\n",
    "        self.layers=[]\n",
    "        for i in range(n):\n",
    "            self.layers.append(EncoderLayer(h=self.h,d_k=self.d_k,d_hidden=self.d_hidden))\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self,x):\n",
    "        for layer in self.layers:\n",
    "            x=layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "    def __init__(self,n=6,h=8,d_k=64,d_hidden=2048,**kwargs):\n",
    "        self.n=n\n",
    "        self.h=h\n",
    "        self.d_k=d_k\n",
    "        self.d_hidden=d_hidden\n",
    "        self.layers=[]\n",
    "        for i in range(n):\n",
    "            self.layers.append(DecoderLayer(h=self.h,d_k=self.d_k,d_hidden=self.d_hidden))\n",
    "        super(Decoder,self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self,x):\n",
    "        y,encoder_output=x\n",
    "        for layer in self.layers:\n",
    "            y=layer([y,encoder_output])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.sequence as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzdata=np.load(\"data.npz\")\n",
    "data=npzdata['data']\n",
    "labels=npzdata['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=150\n",
    "data=sq.pad_sequences(data,maxlen=maxlen,padding='post',truncating='post',dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reshape(data.shape[0],data.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249996, 150, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label={}\n",
    "n=0\n",
    "set_labels=list(set(labels))\n",
    "for l in set_labels:\n",
    "    dict_label[l]=n\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new=[]\n",
    "for l in labels:\n",
    "    labels_new.append(dict_label[l])\n",
    "\n",
    "label_1=np_utils.to_categorical(labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(data,labels,batch_size=32):\n",
    "    nb_instances = data.shape[0]\n",
    "    nb_classes = labels.shape[1]\n",
    "    sample_shape = data[0].shape\n",
    "    batch_data_shape = tuple([batch_size] + list(sample_shape))\n",
    "    batch_label_shape = (batch_size, nb_classes)\n",
    "    # Infinite loop\n",
    "    while True:\n",
    "        # Generate an exploration order\n",
    "        indices = np.arange(nb_instances)\n",
    "\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # Generate batches\n",
    "        imax = int(len(indices) / batch_size)\n",
    "        for i in range(imax):\n",
    "            # Form a batch\n",
    "            x = np.empty(batch_data_shape)\n",
    "            y = np.empty(batch_label_shape)\n",
    "            for j, k in enumerate(indices[i * batch_size: (i + 1) * batch_size]):\n",
    "                x[j] = data[k]\n",
    "                y[j] = labels[k]\n",
    "            if x.shape != batch_data_shape:\n",
    "                print(x.shape)\n",
    "                exit(0)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes=label_1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test =model_selection.train_test_split(data, label_1, test_size=0.33)\n",
    "trainGen=generateData(X_train,y_train)\n",
    "valGen=generateData(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,Flatten\n",
    "from keras.models import Model\n",
    "from keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Input(shape=(150,1),name='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=Encoder(n=6,h=8,d_k=1,d_hidden=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec=Decoder(n=6,h=8,d_k=1,d_hidden=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out=enc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out=dec([x,enc_out])\n",
    "flat_l=Flatten()\n",
    "y_temp=flat_l(dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Dense(nb_classes,activation='softmax',name='output')(y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[x],outputs=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "metrics=['accuracy']\n",
    "optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 150, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_21 (Encoder)            (None, 150, 1)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_20 (Decoder)            [(None, 150, 1), (No 0           input[0][0]                      \n",
      "                                                                 encoder_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 150)          0           decoder_20[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 101)          15251       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,251\n",
      "Trainable params: 15,251\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=trainGen,steps_per_epoch=X_train.shape[0]//32,validation_data=valGen,validation_steps=X_test.shape[0]//32,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
